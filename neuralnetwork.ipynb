{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ecg_plotting import *\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download datasets\n",
    "\n",
    "from dataset_downloader import download_dataset\n",
    "import datasets.ptb_xl.data_handling as ptb_xl_dh\n",
    "\n",
    "download_dataset('backgrounds')\n",
    "download_dataset('ptb_xl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing and Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.ptb_xl.data_handling import get_ecg_array\n",
    "\n",
    "num_samples = 100\n",
    "X, Y_label = get_ecg_array(sampling_rate=500, max_samples=num_samples)\n",
    "X = np.reshape(X[:,452:-452,:],(-1, 4096,12 ,1))\n",
    "Y = np.zeros((num_samples))\n",
    "\n",
    "danger_list = [\"IMI\", \"ASMI\", \"ILMI\", \"AMI\", \"LMI\", \"IPLMI\", \"IPMI\", \"PMI\"]\n",
    "for k in range(num_samples):\n",
    "    if len(set(Y_label['scp_codes'].iloc[k].keys()) & set(danger_list)):\n",
    "        Y[k] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(layers.Layer):\n",
    "    def __init__(self, last_num_filters, **kwargs):\n",
    "        super(Residual, self).__init__(**kwargs)\n",
    "        self.last_num_filters = last_num_filters\n",
    "        \n",
    "        self.layer_1 = layers.Conv2D(last_num_filters + 64, (16, 1), activation=None, padding='same')\n",
    "        self.layer_2 = layers.MaxPooling2D((2, 1)) # CHECK BECAUSE PAPER DOESN'T MENTION PRECISELY\n",
    "        self.layer_3 = layers.BatchNormalization(axis=[1,2]) #? axis = [1,2] to normalize the axis=0 (over the batch)\n",
    "        self.layer_4 = layers.Activation(activation='relu')\n",
    "        self.layer_5 = layers.Dropout(dropout_p) # To prevent overfit\n",
    "        self.layer_6 = layers.Conv2D(last_num_filters + 64, (16, 1), activation=None, padding='same')\n",
    "        self.layer_7 = layers.MaxPooling2D((2, 1)) # CHECK BECAUSE PAPER DOESN'T MENTION PRECISELY\n",
    "        self.layer_8 = layers.BatchNormalization(axis=[1,2]) #? axis = [1,2] to normalize the axis=0 (over the batch)\n",
    "        self.layer_9 = layers.Activation(activation='relu')\n",
    "        self.layer_10 = layers.Dropout(dropout_p) # To prevent overfit\n",
    "\n",
    "        self.layer_11 = layers.Conv2D(last_num_filters + 64, (1, 1), activation=None, padding='same')\n",
    "        self.layer_12 = layers.MaxPooling2D((4, 1)) # CHECK BECAUSE PAPER DOESN'T MENTION PRECISELY\n",
    "        self.layer_13 = layers.BatchNormalization(axis=[1,2]) #? axis = [1,2] to normalize the axis=0 (over the batch)\n",
    "        self.layer_14 = layers.Activation(activation='relu')\n",
    "        self.layer_15 = layers.Dropout(dropout_p) # To prevent overfit\n",
    "\n",
    "    def call(self, x):\n",
    "        # the residual block using Keras functional API\n",
    "        x_backup = x\n",
    "        last_num_filters = self.last_num_filters\n",
    "\n",
    "        x = self.layer_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = self.layer_3(x)\n",
    "        x = self.layer_4(x)\n",
    "        x = self.layer_5(x)\n",
    "        x = self.layer_6(x)\n",
    "        x = self.layer_7(x)\n",
    "        x = self.layer_8(x)\n",
    "        x = self.layer_9(x)\n",
    "        x = self.layer_10(x)\n",
    "\n",
    "        x_backup = self.layer_11(x_backup)\n",
    "        x_backup = self.layer_12(x_backup)\n",
    "        x_backup = self.layer_13(x_backup)\n",
    "        x_backup = self.layer_14(x_backup)\n",
    "        x_backup = self.layer_15(x_backup)\n",
    "        \n",
    "        x = layers.Add()([x,x_backup])\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_p = 0.1\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(64, (16, 1), activation=None, input_shape=(4096, 12, 1)))\n",
    "model.add(layers.BatchNormalization(axis=[1, 2])) #? axis = [1,2] to normalize the axis=0 (over the batch)\n",
    "model.add(layers.Activation(activation='relu'))\n",
    "model.add(layers.Dropout(dropout_p)) # to prevent overfit\n",
    "\n",
    "last_num_filters = 64\n",
    "model.add(Residual(last_num_filters))\n",
    "last_num_filters += 64\n",
    "model.add(Residual(last_num_filters))\n",
    "last_num_filters += 64\n",
    "model.add(Residual(last_num_filters))\n",
    "last_num_filters += 64\n",
    "model.add(Residual(last_num_filters))\n",
    "last_num_filters += 64\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check whether we're training on a GPU or not\n",
    "tf.test.is_gpu_available()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, Y, epochs=40, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8fe47fbcf0df5fb1553eccd10fe68adaaecd5a77378650c47b51c76c16f447a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}